\documentclass{article}

\usepackage{amsmath, amsthm, amssymb}

\newtheorem*{theorem}{Állítás}
\newtheorem*{definition}{Definíció}
\newtheorem*{remark}{Megjegyzés}
\newtheorem*{lemma}{Módszer}

\title{Gépi tanulás a gyakorlatban, előadás vázlat}
\author{Vincze Nándor}
\begin{document}

\maketitle

\section{Bevezető, alapfogalmak}
\begin{definition}[Gépi tanulás]
    Az intelligens viselkedés azon része, amely a tanulás képességén alapul. Minden olyan megoldás,
    ahol a renszer teljesítménye javul a tapasztaltok gyűjétése által.
\end{definition}

\begin{remark}
    $\text{Gépi tanulás} \subset \text{Mesterséges intelligencia}$
\end{remark}

\begin{itemize}
    \item Képfelismerés
    \item Önvezető autó
    \item Ajánlórendszerek
\end{itemize}

\begin{definition}[Gépi tanulás 2]
    Ha adott egy feladat $T$, és egy $P$ teljesítménymetrika, akkor gépi tanulásról beszélünk,
    ha a rendszer egyre több $E$ tapasztalalat hatására a $P$ teljesítménye a $T$ feladaton javul.
\end{definition}
\begin{definition}[Data science]
    Üzleti problémák megoldása, statisztikai elemzések, gépi tanulás alkalmazásával.
\end{definition}
\begin{remark}
    Gépi tanulás esetén egy konkrét feladatot akarunk megoldani minél jobban.
\end{remark}
\begin{definition}
[Felügyelt tanulás]
    Megfigyelés és célérték is áll rendelezésre, a rendszer célja, hogy nem látott
    példákra is a lehető legjobb célértéket jósolja meg.
\end{definition}

\begin{definition}
    [Felügyelelt nélküli tanulás]
    Csak a megfigyelés áll rendelkezésre, a rendszer célja a mintázatok és összefüggések felismerése.
\end{definition}

\begin{definition}
    [Megerősítéses tanulás]
    A rendszer egy környezettel lép kölcsönhatásba, és a visszajelzések alapján tanul.
\end{definition}

\begin{definition}
    [Osztályozási feladat]
    Egyedek előre meghatározott osztályokba való besorolása.
\end{definition}
\begin{definition}
    [Regressziós feladat]
    Az egyedekhez tartozó folytonos célértékek előrejelzése.
\end{definition}
\begin{definition}
    [Jellemzők]
    Az egyedek leíró tulajdonságok. Lehet folytonos vagy diszkrét.
\end{definition}
\begin{definition}
    [Gépi tanulás loop]
    gépi tanulási feladat megoldásának lépései:
    \begin{enumerate}
    \item adatgyűjtés
    \item előfeldolgozás
    \item jellemző kinyerés
    \item modell kiválasztás
    \item tanítás
    \item kiértékelés
    \end{enumerate}
\end{definition}

\newpage

\section{Egyszerű statisztikai döntések}
Az adathalmaz statisztikáiból egyszerű döntési szabályokat hozunk létre.
\textbf{Átlag, szórás, medián, min, max stb...} \\
Hisztogramok, scatter plot.

\begin{definition}
    [Konstans döntés]
    A jellemzőket nem veszzük figyelembe, és csak a célváltozó alapján predikálunk.
    Diszkrét esetben módusz, folytonos esetben átlag.
\end{definition}
\begin{definition}
    [Egyetlen jellemző alapján történő döntés]
    Triviális.
\end{definition}

\begin{definition}
    [Korreláció (pongyola)]
    Két változó közötti \textbf{lineáris} kapcsolat mértéke. $\rho \in [-1, 1]$
\end{definition}
A jellemzők kiválasztására több módszer is létezik, pl $\chi^2$ teszt.

\newpage
\section{Osztályozási feladatok, döntési fák}
Osztályozási feladat példák, train/test split, metrikák.

\begin{definition}
    [$k$-fold cross validation]
    Az adathalmazt $k$ részre bontjuk, és $k$ iterációt/kisérletet futtatunk.
    Minden itrációban pontosan 1 részhalmazt használunk tesztelésre, a maradék $k-1$ részhalmnazt
    tanításra. Ekkor minden egyed pontosan egyszer kerül a teszthalmazba.
\end{definition}

\begin{definition}
    [Confusion matrix]
    \begin{tabular}{c|c|c}
                & Igaz pozitív & Igaz negatív \\
        \hline
    Predikált pozitív & TP & FP \\
    Predikált negatív & FN & TN \\
    \end{tabular}
\end{definition}

\begin{definition}
    [Accuracy]
    $acc = \frac{TP + TN}{TP + TN + FP + FN}$
\end{definition}
\begin{definition}
    [Precision]
    $prec = \frac{TP}{TP + FP}$
\end{definition}
\begin{definition}
    [Recall]
    $recall = \frac{TP}{TP + FN}$
\end{definition}
\begin{definition}
    [F1 score]
    $F1 = 2 \cdot \frac{prec \cdot recall}{prec + recall}$
\end{definition}
\begin{definition}
    [Döntési fa]
    Egy olyan tanuló algorimtus, ami egy fa struktúra alapján osztályozási feladatot lát el.
    A belső csúcsok jellemzőkkel cimkézettek, melyek szerint a bemeneti egyedeket szétválasztjuk.
    A levelek az adott szétválasztások szerint predikált osztálycímkék.\\
    Folytonos és dikszkrét jellemzők esetén is alkalmazható.\\
    Néhány jellemző:
    \begin{itemize}
        \item nem minden jellemző kerül felhasználásra
        \item a levelek mélysége nem azonos
        \item jól vizualizálható
        \item explicit szabályokat tanul meg a jellemzők közötti
        \\ \\ DE
        \item greedy algorimtus
        \item sok jellemző esetén sok példa kell
    \end{itemize}
\end{definition}
\begin{definition}
    [Erdő osztályozó]
    Több, kisebb döntési fa együttes szavazata alapján jön létre a végső predikció.
\end{definition}
\newpage

\section{Text mining és lineáris gépek}
Strukturálatlan szöveges adatok automatikus feldolgozása. Több nehézség, mint a szinonímaszavak, szlengek,
nyelvjárások, hibák stb\dots\\
Néhány alkalmazása:
\begin{itemize}
    \item chatbot
    \item fordítás
    \item informácio kinyerés
    \item dokumentum osztályozás
    \item spam szűrés
\end{itemize}
\begin{lemma}
    [Szövegek előfeldolgozása]
    \begin{enumerate}
    \item Tokenizálás: szavakra bontás
    \item Normalizálás: kis/nagybetű, ékezetek stb\dots
    \item Lemmatizálás: szótőkinyerés, vagy Stemming: ragok egyszerű levágása
    \item írásjelek eltávolítása
    \item Stopszó szűrés: kötőszavak, névelők, jelentés nélküli
    \item POS tagging: szófajok megjelölése    
    \end{enumerate}
\end{lemma}

\begin{lemma}
    [Szózsák modell]
    Dokumentumok osztályoza során egy szótárat készítünk, az összes előfordulő szóból,
    majd az egyes dokumentumokat a szótárból megjelenő szavak előfordulási gyakoriságával jellemezzük.\\
    \textbf{A szavak sorrendje elveszik.} Ez megoldható ha n-grammokat is használunk, kizárólag unigrammo helyett.
\end{lemma}

\begin{definition}
    [Term frequency - inverse document frequency]
    Szeretnénk, hogy azon szavak amelyek több dokumentumban is előfordulnak, kisebb súlyt kapjanak.
    Legyen adott $w$ szó, $d$ dokumentum, $D$ az összes dokumentum halmaza, $tf(w, d)$  a $w$ szó előfordulási gyakorisága a $D$ dokumentumban,
    $df(w, D)$ pedig azon dokumentumok száma az $D$ halmazban, amelyek tartalmazzák a $w$ szót. \\
    Ekkor a TF-IDF súlyozás:
    \[
    TF\_IDF(w, d) = tf(w,d)*log\left(\frac{1}{df(w, D)}\right)
    \]
\end{definition}

\begin{definition}
    [Lineáris osztályozó]
    Egy adott $n$ dimenziós jellemző térben egy hipersík segítségével választja szét az osztályokat.
    A hipersík egyenlete:
    \[
    w_1x_1 + w_2x_2 + ... + w_nx_n + b = 0
    \]
    ahol $w_i$ a súlyok, $b$ az eltolás, megtanulandó paraméterek a predikcióhoz.
    Az osztályozás a következőképpen történik:
    \[
    f:\mathbb{R}^n \to \{-1, 1\}, \quad f(x) = sign(w \cdot x + b)
    \]
    ahol $f(x) = 1$ az egyik osztály, $f(x) = -1$ a másik osztály.
\end{definition}

\begin{definition}
    [Diszkriminatív vs. generatív módszerek]
    A diszkriminatív modellek (mint a lineáris gépek) célja, hogy minél pontosabban
    elválasszák az osztályokat, míg a generatív modellek (mint a döntési fák) a bemeneti adatok
    eloszlását próbálják modellezni az egyes osztályokra külön-külön.
\end{definition}
\begin{remark}
    A lineáris gépek sok jellemzőt tudnak kezelni, ezek mind hozzájárulnak a döntéshez,
    viszont ha nem lineáris a változók közötti kapcsolat, akkor gyenge lesz a modell.
\end{remark}

\newpage
\section{Deep learning}
Egy olyan gépi tanulási módszer, mely során több rejtett rétegből álló
mesterséges neurális hálókat alkalmazunk.
\begin{definition}
    [Neuron]
    \[
    y = f\left(\sum_{i=1}^{n} w_i x_i + b\right)
    \]
    ahol $f$ a nem-lineáris aktivációs függvény, $n$ a bemenetek száma, $w_i$ a súlyok, $b$ az eltolás,
    $x_i$ a bemenetek, $y$ a kimenet.
    \\
    Egy nurális háló tanítása alatt a $w_i$ és $b$ paraméterek olyan beállítását értjük,
    amikor a \textbf{hibafüggvény} értéke minimális.
\end{definition}

\begin{definition}
    [Hibafüggvény]
    Számszerűsíti a modell predikciójának pontatlanságát.\\
    Ez lehet MSE, Cross entropy stb\dots
\end{definition}

\begin{definition}
    [Epoch]
    Az adathalmazon történő egy teljes tanulási ciklus.
\end{definition}

Intuíciót erőltetve a rétegek értelmezésére, az első rétegek végzik az "automatikus"
jellemzőkinyerést, míg a későbbi rétegek már ezekkel a jellemzőkkel dolgoznak.

\begin{definition}
    [Konvolúciós neurális háló (CNN)]
    Olyan neurális háló, amely konvolúciós rétegeket is tartalmaz.
    Ezek a rétegek kis szűrőket alkalmaznak a bemeneti adatokra,
    hogy helyi jellemzőket nyerjenek ki. Gyakran használják képfeldolgozási feladatokban.
\end{definition}

A mély gépi tanulás előnyei a klasszikus módszerekkel szemben:\\
képesek nyers adatokkal dolgozni és változatos feladatokat meg tudnak oldani.\\
Cserébe sok adat szükséges a tanítsához, ami meglehtősen számításigényes, valamint black-box.

\newpage
\section{Reprezentáció tanulás, autodecoder}
Olyan módszerek amelyek célja, hogy a bemeneti adatoknak egy hatékony elkódolását tanulják meg.
Jellemzően a cél, hogy egy adott egyedet egy beágyazási vektorral jellemezzünk, amely 
magában hordozza az adott egyed fontos tulajdonságait.
\begin{definition}
    [Önfelügyelt tanulás]
    Olyan tanulási paradigma, ahol a modell a bemeneti adatok egy részét használja fel
    a bemenetként, míg a bemeneti adatok másik részét célértékként. Így a modell képes
    megtanulni a bemeneti adatok belső struktúráját anélkül, hogy külső címkékre lenne szükség.

\end{definition}
\begin{lemma}
    [Szóbeágyazások]
    \textbf{word2vec}\\
    Cél: van egy szótárunk, amely minden eleméhez egy megfelelő vektort rendelünk. Szeretnénk, hogy a hasonló jelentésú
    szavakhoz közeli vektorok tartozzanak.\\
    \begin{itemize}
        \item CBOW (continuous bag of words): adott egy adott szó környezete,
        a cél, hogy a környezetből megjósoljuk a középső szót (jegyzetben 5 szó)
        \item Skip-gram: adott egy szó, a cél, hogy megjósoljuk a környezetében található szavakat
    \end{itemize}
\end{lemma}
\begin{lemma}
    [LLM-ek]
    A word2vec megközelítések a szavak jelentését statikusan tárolják. A nagy nyelvi modellek ezzel ellentétben
    teljes mondatok vagy bekezdések reprezentációját tanulják meg. A szóbeágyazások itt kontextusfüggőek.
\end{lemma}
\begin{definition}
    [BERT modellek]
    Amikor egy szöveget akarunk elemezni, ismerjük a teljes szöveget, így a tanítás során egy adott szót letakarunk (maszkolunk),
    és a cél, hogy a modell a környező szavak alapján megjósolja a letakart szót.
\end{definition}
\begin{definition}
    [GPT modellek]
    Amikor szövegek generálása cél, akkor egy szónak csakis a baloldali környezete ismert, ez alapján kell megjósolni a követzkező szót.
    Itt használjuk a transzformer architektúrát. (???)
\end{definition}
\begin{definition}
    [autodencoder]
    Olyan neurális háló, amely egy adott bemenetet kódol (jellemzően alacsonyabb dimenzióba), majd visszakódolja.
    A cél, hogy a kimenet az eredeti bemenet legyen.
\end{definition}
\newpage

\section{Fine-tuning és generatív mesterséges intelligencia}
Rendelkezésre állnak előre betanított modellek, amelyek szöveg-, vagy képfeldolgozási beágyazásokat végeznek.
A kódolás eredményét felhasználhatjuk egy adott feladathoz tartozó modell betanításához.
Ekkor az alsó rétegekben a betanított súlyokat használjuk, míg a felső rétegek súlyait véletlenszerűen inicializáljuk.
A tanulás során természetesen az alsó rétegek súlyait is módosítjuk, vagyis \textbf{finomhangoljuk} az eredeti modellt.

\subsection{Szöveggenerálás}
A GPT típusú modellek az internetetn előtanított beágyazások segítségével képesek adott szósorozathoz megjósolni a
következő szót a lehetséges angol szavak szótárából. Ezt egy osztályozási feladatként kezelik, vagyis
a modell megadja a legvalószínűbb következő szót.


A ChatGPT egy finomhangolt GPT modell, ahol emberi visszajelzések alapján tovább tanították a modellt,
így képes a felhasználóval folytatott párbeszédre.

\subsection{Képgenerálás}
Ennek az alapjai is egy generálásra finomhangolt beágyazás. Lényegében a tanítópéldák képek, amelyek bizonyos
részeit letakarjuk, és a modell feladata a hiányzó pixelek kiegészítése.

\subsection{Képgenerálás instruckió alapján}
Az előző két módszer ötvözete: egy szöveges leírást (instruckiót) kap a modell, és egy kép generálását kell elvégeznie.
Itt a szöveges leírást egy előre betanított szöveg beágyazó modell segítségével kódolják.

A diffútiós modellek visszavezetik a generálási feladatot egy zajmentesítési feladatra.
Az alapgondolat az, hogy van egy zajos képünk, de tudjuk annak tartalmát (szövegesen megadva),
akkor a szöveges leírás alapján még a nagyon zajos képekből is helyre tudunk állítani egy képet, ami megfelel a leírásnak.
Ez szintén egy önfelügyelt tanuálási megoldás, hiszen a tanítópéldák képeiből mesterségesen zajosítunk képeket, és a modell feladata a zajmentesítés.

\section{Képfeldolgozás és lokális osztályozók}
\begin{definition}
    [Képosztáylozás]
    Egy adott képhez tartozó címke (pl.: kutya, macska, autó stb\dots) predikálása.
\end{definition}
\begin{definition}
    [Objektum detektálás]
    Egy adott képen található objektumok helyének és címkéjének meghatározása.
\end{definition}
\begin{definition}
    [Augmented reality]
    Egy technológia, amely a valóságot kiegészíti digitális információkkal.
\end{definition}
\begin{remark}
    Az előfeldolgozás kiemelten fontos képes esetén, és eltérő lehet
    a felhasználási területtől függően.\\
    \textit{egységes méret, színcsatorna egységesítés}\\
    Néhány példa a képek jellemzésére:\\
    \begin{itemize}
        \item két kép között a távolságot az egyes pixelek páronkénti hasonlósága alapján adjuk meg (pixelvektorok, hasonló struktúrájú képek esetén működik)
        \item a kép színeloszlását histogramokkal jellemezzük
        \item képfeldolgozási eszközökkel kinyerhetünk alacsony szintű jellemzőket (élek, sarkok, textúrák stb\dots)
        majd a szózsák modellhez hasonlóan jellemezhetjük a képeket
        \item mély neurális hálók segítségével, az utolsó előtti réteg kimenetét használhatjuk jellemzőként
    \end{itemize}
\end{remark}
\begin{definition}
    [KNN]
    Ha adott egy távolság metrika, akkor a jellemzőtérben, valós időeben megkeressük
    a legközelebbi $k$ tanító példát, és ezek címkéinek többségi szavazata alapján predikálunk.
    
    Érzékeny a jellemzők skálázására, így érdemes normalizálni az adatokat, illetve dimenzionalitás problémája itt is fenáll.
\end{definition}

\newpage
\section{Regressziós feladat}
Olyna gépi tanulási probléma, ahol a célváltozó folytonos értékű.

\begin{definition}
    [MSE]
    \[
    MSE  = \frac{1}{n}\sum_{i=1}^{n}(y_i-\hat{y}_i)^2
    \]
    Ahol $y_i$ a predikált érték, $\hat{y}_i$ a valós érték, $n$ a példák száma.
\end{definition}
\begin{definition}
    [lineáris regresszió]
    Egy olyan regressziós modell, ahol a célváltozó lineáris függvénye a bemeneti változóknak.
\end{definition}
\begin{definition}
    [regressziós döntési fa]
    Hasonlóan a döntési fához, de a levelekben folytonos értékek találhatók,
    a köztes csűcsokben pedig egy-egy regressziós modell, ami egy jellemző mentén 
    osztja szét az adatokat.
\end{definition}
\begin{definition}
    [Regressziós KNN]
    Hasonlóan az osztályozási KNN-hez, de a legközelebbi $k$ példa
    alapján prediktálja az érttékeket, lényegében a $k$ példa célértékeinek átlagát veszi.
\end{definition}

\newpage
\section{Túltanulás}
\begin{definition}
    [Torzítás]
    A modell tanítóadatbázison számított hibája.\\
    \textit{Magas torzítás esetén a modell nem képes jól megtanulni a tanító adatokat.}
\end{definition}
\begin{definition}
    [Variancia]
    A modell tesztadatbázison számított hibája és a tanító adatbázison számított hiba különbsége.\\
\end{definition}
\begin{definition}
    [Tórzítás-variancia dilemma]
    A modell torzítása és varianciája közötti kiegyensúlyozás.
\end{definition}
Néhány gyakorlati példa:\\
\begin{itemize}
    \item Döntési fa: a fa magassága
    \item Lináris gép: a hibafüggvényhez hozzávesszük a súlyok valamilyen függvényét (L1, L2 regularizáció)
    \item KNN: a $k$ értéke
    \item Neurális háló: rétegek száma, neuronok száma, dropout, korai leállítás
\end{itemize}
\begin{definition}
    [Validációs halmaz]
    Meta-paraméterek finomhangolás során használatos. Az adathalmazt három részre bonrjuk: tanító, validációs, teszt.
    A paraméterek a tanító és validációs halmazon kerülnek beállításra, majd a teszt halmazon
    kerül kiértékelésre a végső modell.
\end{definition}

\newpage
\section{Reinforcement learning}
Mestint I. alapú elvek: Egy ágens interaktál a környezetével, és az állapot megváltozása után
visszajelzést kap. Az ágens célja, hogy maximalizálja a hosszútávú jutalmat.

\begin{definition}
    [Exploration vs. exploitation]
    Exploration: új, még nem ismert lehetőségek keresése.
    Exploitation: már ismert, jól működő lehetőségek kihasználása.
\end{definition}
\begin{definition}
    [$\epsilon$-greedy stratégia]
    Az ágens $\epsilon$ valószínűséggel véletlenszerűen választ egy lehetőséget (exploration),
    és $1-\epsilon$ valószínűséggel választja ki a legjobbnak tűnő lehetőséget (exploitation).
\end{definition}
\begin{definition}
    [Value-based módszerek]
    Az érték-alapú módszerek egy adott állapotból kiinduló összes akcióhoz egy értéket tanulnak,
    ami azt próbálja megbecsülni, hogy az adott állapotból az adott akció hatására mennyi jutalmat lehet összeszedni a jövőben.
\end{definition}
\begin{definition}
    [Policy-based módszerek]
    A stratégia-alapú módszerek közvetlenül az egyes döntések valószínűségét próbálják megbecsülni
    a jövőben összeszedhető jutalom ismerete nélkül.
\end{definition}
\begin{remark}
    Amennyiben már rendelkezésre áll egy a saját feladatunkban használt adattípushoz (kép, szöveg, stb...)
    előre betanított modell, akkor elhagyva az utolsó réteget, egy megfelelő beágyazást kaphatunk,
    amit felhasználhatunk a saját feladatunkhoz.\\
    \textit{Mindenképp figyelni kell arra, hogy habár az adattípus azonos, nem biztos,
    a saját célunknak megfelelő beágyazást kapunk.}
\end{remark}
\end{document}
